{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "163c813e-da1c-47e9-8e15-bcc87f2cfac1",
   "metadata": {},
   "source": [
    "## Lead / Lag Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bad56007-178c-4325-8873-7415a18b5aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import os\n",
    "import numpy as np\n",
    "import netCDF4 as nc\n",
    "import pandas as pd\n",
    "from scipy import stats \n",
    "from scipy.interpolate import griddata, RectBivariateSpline\n",
    "import matplotlib.pyplot as plt \n",
    "import statistics\n",
    "#import seaborn as sns\n",
    "from tqdm.auto import tqdm \n",
    "import operator as op\n",
    "import cartopy as cart\n",
    "import matplotlib.ticker as mticker\n",
    "#from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import pyproj\n",
    "#from mpl_toolkits.basemap import Basemap, interp\n",
    "import matplotlib.colors as colors\n",
    "from matplotlib.axes import Axes\n",
    "from cartopy.mpl.geoaxes import GeoAxes\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "from scipy.stats import kstest, mannwhitneyu, ks_2samp\n",
    "GeoAxes._pcolormesh_patched = Axes.pcolormesh\n",
    "import matplotlib.dates as mdates\n",
    "import cartopy\n",
    "import cartopy.feature as cfeature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ed680d-03b6-4fc4-8901-120628d0a5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5b63b7-efd0-4525-8a99-1c5733f6249b",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = (15, 15)\n",
    "longdis = 15\n",
    "latdis = 15\n",
    "resolution = '10m'\n",
    "\n",
    "# Map generation Code\n",
    "def generateMap(central_longitude=0):\n",
    "    \n",
    "    fig = plt.figure(figsize=size)\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax = plt.axes(projection=ccrs.PlateCarree(central_longitude=central_longitude))\n",
    "    ax.coastlines()\n",
    "    gl = ax.gridlines(ccrs.PlateCarree(), draw_labels=True, linewidth=0.5, color='gray', alpha=0.5, linestyle='--')\n",
    "    gl.xlabels_top = False\n",
    "    gl.xlocator = mticker.FixedLocator((range(-180, 180, longdis)))\n",
    "    gl.ylocator = mticker.FixedLocator((range(-90, 90, latdis)))\n",
    "    gl.xformatter = LONGITUDE_FORMATTER\n",
    "    gl.yformatter = LATITUDE_FORMATTER\n",
    "    \n",
    "    ax.add_feature(cart.feature.BORDERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7837eedf-5327-4b00-ba8f-24fdee9ebd98",
   "metadata": {},
   "source": [
    "# Loading in the Data\n",
    "### Note: update according to your file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d96fa4-8aaa-4bbb-848e-1081a8f729d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ERA5/precip_dailytotal\n",
    "#first re-grid on 360x180 grid with 1x1 gridcells\n",
    "yearly_precip_regridded = xr.open_dataset('precip_daily_total_1979-2019_regrid.nc', engine='netcdf4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6ca536-5999-4a51-95be-2dd79a3425c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert ERA5 precipitation to mm\n",
    "yearly_precip_regridded = yearly_precip_regridded.tp*1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884d04e7-e1a7-49eb-b0a9-8578c8ea83a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ..\n",
    "%cd humid_heat\\regridded_daymeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e51e83-f318-46a1-8494-6487c0849475",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tw_regridded = xr.open_dataset('TW_daily_max_1979-2020_daymean_regridded.nc', engine='netcdf4')\n",
    "#all_tw_regridded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec2de7e-8338-484b-91c5-b1510cc9b329",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ..\n",
    "%cd ..\n",
    "%cd ..\n",
    "daily_precip_regrid = xr.open_dataset('NOAA_CPC/precip_daily_total_1979-2022_regrid.nc', engine='netcdf4')\n",
    "#daily_precip_regrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee4f72c-321e-432b-bd15-fe209fab8854",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%cd RainHeatData\n",
    "%cd ERA5/2mtemp_dailymean/processed\n",
    "#2mtemp_dailymax from ERA5\n",
    "temp_dailymean = xr.open_dataset('2mtemp_dailymean_1979-2019_regridded.nc', engine='netcdf4')\n",
    "#temp_dailymean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fd8976-c075-4efd-a81e-c6dd39f15e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ..\n",
    "%cd ..\n",
    "%cd specific_humidity_dailymean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876f61a0-40d5-4b68-baca-2b1fe8c0c68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spechum_dailymean = xr.open_dataset('spechum_dailymean_1979-2019_regrid.nc', engine='netcdf4')\n",
    "#spechum_dailymean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1970f7c-39bb-4ead-b81f-fd27a9c679c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vertical velocity\n",
    "%cd ..\n",
    "vv = xr.open_dataset('vertical_velocity_500hPa_1979-2023_regridded.nc',engine='netcdf4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ea507a-3344-436b-a98f-57798c560c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#soil moisture\n",
    "soil = xr.open_dataset('swv_dailymean_1979-2021_regridded.nc',engine='netcdf4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c92f2b-3143-4968-918f-1f1384837e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ERA5 Northern Hemisphere\n",
    "lats = np.argwhere((yearly_precip_regridded.lat.values >= 0) & (yearly_precip_regridded.lat.values <= 90))\n",
    "lons = np.argwhere((yearly_precip_regridded.lon.values >= 0) & (yearly_precip_regridded.lon.values <= 360))\n",
    "precip_data_N = yearly_precip_regridded.sel(lon = slice(0,360), lat=slice(0,90)) #yearly_precip_regridded\n",
    "TW_data_N = all_tw_regridded.sel(lon = slice(0,360), lat=slice(0,90))\n",
    "soil_N = soil.sel(lon = slice(0,360), lat=slice(0,90))\n",
    "#temp_data_N = temp_dailymean.sel(lon = slice(0,360), lat=slice(0,90))\n",
    "#spechum_data_N = spechum_dailymean.sel(lon = slice(0,360), lat=slice(0,90))\n",
    "#vv_data_N = vv.sel(lon = slice(0,360), lat=slice(0,90))\n",
    "\n",
    "#Southern Hemisphere\n",
    "#lats = np.argwhere((yearly_precip_regridded.lat.values >= -90) & (yearly_precip_regridded.lat.values <= 0))\n",
    "#lons = np.argwhere((yearly_precip_regridded.lon.values >= 0) & (yearly_precip_regridded.lon.values <= 360))\n",
    "#precip_data_S = yearly_precip_regridded.sel(lon = slice(0,360), lat=slice(-90,0)) #yearly_precip_regridded\n",
    "#TW_data_S = all_tw_regridded.sel(lon = slice(0,360), lat=slice(-90,0))\n",
    "#temp_data = temp_dailymean.sel(lon = slice(0,360), lat=slice(-90,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98db998-b84c-4360-ae87-4184a5381fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "june_months = np.argwhere((yearly_precip_regridded.time.values.astype('datetime64[M]').astype(int) % 12 + 1) == 6)\n",
    "july_months = np.argwhere((yearly_precip_regridded.time.values.astype('datetime64[M]').astype(int) % 12 + 1) == 7)\n",
    "august_months = np.argwhere((yearly_precip_regridded.time.values.astype('datetime64[M]').astype(int) % 12 + 1) == 8)\n",
    "JJA_idx = np.concatenate([june_months, july_months, august_months])\n",
    "JJA_idx\n",
    "\n",
    "december_months = np.argwhere((yearly_precip_regridded.time.values.astype('datetime64[M]').astype(int) % 12 + 1) == 12)\n",
    "january_months = np.argwhere((yearly_precip_regridded.time.values.astype('datetime64[M]').astype(int) % 12 + 1) == 1)\n",
    "february_months = np.argwhere((yearly_precip_regridded.time.values.astype('datetime64[M]').astype(int) % 12 + 1) == 2)\n",
    "DJF_idx = np.concatenate([december_months, january_months, february_months])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa3b701-b863-49e9-b5ae-8372a283ab76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select summer months\n",
    "precip_data_JJA = precip_data_N.where(precip_data_N.time.dt.month.isin([6,7,8]),drop=True) #tp for ERA5, precip for NOAA\n",
    "TW_data_JJA = TW_data_N.where(TW_data_N.time.dt.month.isin([6,7,8]),drop=True).TW\n",
    "#temp_data_JJA = temp_data_N.where(temp_data_N.time.dt.month.isin([6,7,8]),drop=True).t2m\n",
    "#spechum_data_JJA = spechum_data_N.where(spechum_data_N.time.dt.month.isin([6,7,8]),drop=True).q\n",
    "#vv_data_JJ = vv.where(vv_data_N.time.dt.month.isin([6,7,8]),drop=True).w\n",
    "soil_data_JJ = soil.where(soil_N.time.dt.month.isin([6,7,8]),drop=True).swvl1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7342b78b-dd1a-4453-a15c-99533104cd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "### select data for 1 x 1 grid points ###\n",
    "## ONLY IF DOING ONE POINT SELECTION\n",
    "\n",
    "#input location coordinates: Phoenix (33.5, 248.5)\n",
    "input_lon=248.5\n",
    "input_lat=33.5\n",
    "\n",
    "precip_data = precip_data_JJA.sel(lon =slice(input_lon-.1,input_lon+.1), lat=slice(input_lat-.1,input_lat+.1))\n",
    "precip_data_year = precip_data_N.sel(lon =slice(input_lon-.1,input_lon+.1), lat=slice(input_lat-.1,input_lat+.1))\n",
    "#.mean(dim=['lat','lon'])\n",
    "TW_data = TW_data_N.sel(lon =slice(input_lon-.1,input_lon+.1), lat=slice(input_lat-.1,input_lat+.1)).TW\n",
    "#.mean(dim=['lat','lon'])\n",
    "temp_data = temp_data_N.sel(lon =slice(input_lon-.1,input_lon+.1), lat=slice(input_lat-.1,input_lat+.1)).t2m\n",
    "spechum_data = spechum_data_N.sel(lon =slice(input_lon-.1,input_lon+.1), lat=slice(input_lat-.1,input_lat+.1)).q\n",
    "#precip_data\n",
    "vv_data = vv_data_N.sel(lon =slice(input_lon-.1,input_lon+.1), lat=slice(input_lat-.1,input_lat+.1)).w\n",
    "soil_data = soil_N.sel(lon =slice(input_lon-.1,input_lon+.1), lat=slice(input_lat-.1,input_lat+.1)).swvl1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90801051-3957-4384-8ad3-2bf9bdd832ec",
   "metadata": {},
   "source": [
    "## 3 regions of focus\n",
    "* Region 1: Southern Arizona: 32-34N, 243-250E (try 32-38N) -- NEW COORD: 32-37N, 243-248E\n",
    "* Region 2: East James Bay to US-Canada Border: 48-54N, 270-290E\n",
    "* Region 2 updated: 49-55N, 282-289 N\n",
    "* Region 3: Calcutta & Dhaka: 22-24N, 87-90E\n",
    "* Region 4 (supplemental): Morocco:  20-30N, 0-10E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4c5371-ca1c-467c-8717-94fe82c752c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### select area to average over ###\n",
    "# REGIONALLY AVERAGED SELECTIONS\n",
    "\n",
    "#lats = np.argwhere((yearly_precip_regridded.lat.values >= 32.5) & (yearly_precip_regridded.lat.values <= 34.5))\n",
    "#lons = np.argwhere((yearly_precip_regridded.lon.values >= 289.5) & (yearly_precip_regridded.lon.values <= 293.5))\n",
    "\n",
    "lon_1=87.5\n",
    "lon_2=90.5\n",
    "lat_1=22.5\n",
    "lat_2=24.5\n",
    "\n",
    "precip_data = precip_data_JJA.sel(lon =slice(lon_1-.1,lon_2+.1), lat=slice(lat_1-.1,lat_2+.1))\n",
    "precip_data_year = precip_data_N.sel(lon =slice(lon_1-.1,lon_2+.1), lat=slice(lat_1-.1,lat_2+.1)).mean(dim=['lat','lon'])\n",
    "TW_data = TW_data_N.sel(lon =slice(lon_1-.1,lon_2+.1), lat=slice(lat_1-.1,lat_2+.1)).TW.mean(dim=['lat','lon'])\n",
    "#temp_data = temp_data_N.sel(lon =slice(lon_1-.1,lon_2+.1), lat=slice(lat_1-.1,lat_2+.1)).t2m.mean(dim=['lat','lon'])\n",
    "#spechum_data = spechum_data_N.sel(lon =slice(lon_1-.1,lon_2+.1), lat=slice(lat_1-.1,lat_2+.1)).q.mean(dim=['lat','lon'])\n",
    "vv_data = vv_data_N.sel(lon =slice(lon_1-.1,lon_2+.1), lat=slice(lat_1-.1,lat_2+.1)).w.mean(dim=['lat','lon'])\n",
    "soil_data = soil_N.sel(lon =slice(lon_1-.1,lon_2+.1), lat=slice(lat_1-.1,lat_2+.1)).swvl1.mean(dim=['lat','lon'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536f603e-470b-4bd7-af6e-e5eaa46f8fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Daily Precip Anomalies ###\n",
    "#daily average\n",
    "precip_mean = precip_data.groupby('time.dayofyear').mean(dim='time')\n",
    "#30 day rolling mean\n",
    "precip_rolling = precip_data.rolling(time = 30, center = True).mean('time')\n",
    "#anomaly\n",
    "precip_data_anom = precip_data.groupby('time.dayofyear') - precip_rolling.groupby('time.dayofyear').mean(dim='time')\n",
    "\n",
    "### Daily Max TW Anomalies ###\n",
    "#daily average\n",
    "TW_mean = TW_data.groupby('time.dayofyear').mean(dim='time')\n",
    "#rolling mean\n",
    "TW_rolling = TW_data.rolling(time = 30, center = True).mean('time')\n",
    "\n",
    "#anomalies -- with 5 day smoothed climatology and without\n",
    "TW_anom = TW_data.groupby('time.dayofyear') - TW_rolling.groupby('time.dayofyear').mean(dim='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b3ffa0-0c78-4cd4-9974-5816dc9f229c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#only select unique TW data\n",
    "_, index = np.unique(TW_anom['time'], return_index = True)\n",
    "TW_unique = TW_anom.isel(time=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5563a4b-aa28-4c64-b15f-4b17a5da4673",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Daily 2m Temperature Anomalies ###\n",
    "#daily average\n",
    "temp_mean = temp_data.groupby('time.dayofyear').mean(dim='time')\n",
    "#rolling mean\n",
    "temp_rolling = temp_data.rolling(time = 30, center = True).mean('time')\n",
    "\n",
    "#anomalies -- with 5 day smoothed climatology and without\n",
    "temp_data = temp_data.groupby('time.dayofyear') - temp_rolling.groupby('time.dayofyear').mean(dim='time')\n",
    "\n",
    "### Daily Mean Specific Humidity Anomalies ###\n",
    "#daily average\n",
    "spechum_mean = spechum_data.groupby('time.dayofyear').mean(dim='time')\n",
    "#rolling mean\n",
    "spechum_rolling = spechum_data.rolling(time = 30, center = True).mean('time')\n",
    "\n",
    "#anomalies -- with 5 day smoothed climatology and without\n",
    "spechum_data = spechum_data.groupby('time.dayofyear') - spechum_rolling.groupby('time.dayofyear').mean(dim='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3faad81-e781-44a2-a433-8c161fec2484",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get abs magnitudes\n",
    "vv_mag = vv_data\n",
    "soil_mag = soil_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add02583-185d-41b2-a34f-4464e69a8998",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vv\n",
    "vv_mean = vv_data.groupby('time.dayofyear').mean(dim='time')\n",
    "vv_rolling = vv_data.rolling(time = 30, center = True).mean('time')\n",
    "vv_data = vv_data.groupby('time.dayofyear') - vv_rolling.groupby('time.dayofyear').mean(dim='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b98c511-7ebf-4bb4-af5b-22f604fe98f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#soil m\n",
    "soil_mean = soil_data.groupby('time.dayofyear').mean(dim='time')\n",
    "soil_rolling = soil_data.rolling(time = 30, center = True).mean('time')\n",
    "soil_data = soil_data.groupby('time.dayofyear') - soil_rolling.groupby('time.dayofyear').mean(dim='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a820cd0-f640-4d7f-9707-84073c8b8deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change if you want magnitude of anomaly\n",
    "_, index = np.unique(vv_data['time'], return_index = True)\n",
    "vv_unique = vv_data.isel(time=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f5d988-7dbb-4b1d-b4d4-df98ca2e5b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, index = np.unique(soil_data['time'], return_index = True)\n",
    "soil_unique = soil_data.isel(time=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca48d87-0a52-4567-8b2e-0579c6a0ba2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#90th percentile cutoffs for each variable\n",
    "# for anomalies use variable_data\n",
    "# for abs magnitude use variable_mean\n",
    "percentile_cutoff_JJA = np.nanpercentile(np.squeeze(precip_data), q=90, axis=0)\n",
    "TW_percentile_cutoff_JJA = np.nanpercentile(np.squeeze(TW_unique), q=90, axis=0)\n",
    "#temp_percentile_cutoff_JJA = np.nanpercentile(np.squeeze(temp_data), q=90, axis=0)\n",
    "#spechum_percentile_cutoff_JJA = np.nanpercentile(np.squeeze(spechum_data), q=90, axis=0)\n",
    "#TW_percentile_cutoff_JJA\n",
    "#vv_percentile_cutoff_JJA = np.nanpercentile(np.squeeze(vv_unique), q=90, axis=0)\n",
    "soil_percentile_cutoff_JJA = np.nanpercentile(np.squeeze(soil_unique), q=90, axis=0)\n",
    "soil_percentile_cutoff_JJA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfad1b4-659d-45f9-821e-24b0b5e62fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### percentile of wet days >1 mm for area averaged ###\n",
    "\n",
    "raw_percentile_cutoff_JJA = np.zeros((precip_data_JJA.shape[1], precip_data_JJA.shape[2]))\n",
    "precip_days=[]\n",
    "rain_threshold = 1\n",
    "for i in range(precip_data.shape[1]):\n",
    "    \n",
    "    for j in range(precip_data.shape[2]):\n",
    "        \n",
    "        precip_data_for_coordinate = precip_data[:,i,j]\n",
    "        idx_norain = np.squeeze(np.argwhere(np.array(precip_data_for_coordinate) <= rain_threshold))\n",
    "        precip_data_JJA_pc = precip_data_for_coordinate[~idx_norain] #this is still an xarray, all days for given coord that have precip>1mm rain\n",
    "        raw_percentile_cutoff_JJA[i][j] = np.nanpercentile(precip_data_JJA_pc, q=90)\n",
    "        idx_90 = np.squeeze(np.argwhere(np.array(precip_data_for_coordinate) > raw_percentile_cutoff_JJA[i][j])) # put into index array\n",
    "        precip_90_pc = precip_data_for_coordinate[idx_90] # select precip anomalies for this index\n",
    "        precip_90_idx = precip_90_pc.time.to_dataframe() # put into dataframe, list of dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828d77b3-cea6-4e7c-84da-65f9f8406630",
   "metadata": {},
   "outputs": [],
   "source": [
    "TW_data_JJA.shape\n",
    "TW_data_coords = TW_data_JJA.sel(lon =slice(lon_1-.1,lon_2+.1), lat=slice(lat_1-.1,lat_2+.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e864657e-3715-4e06-b9f0-f9a885a38b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "### percentile of TW days ###\n",
    "\n",
    "TW_percentile_cutoff_JJA = np.zeros((TW_data_JJA.shape[2], TW_data_JJA.shape[1]))\n",
    "TW_days=[]\n",
    "threshold = 0.001\n",
    "for i in range(TW_data_coords.shape[2]):\n",
    "    \n",
    "    for j in range(TW_data_coords.shape[1]):\n",
    "        \n",
    "        TW_data_for_coordinate = TW_data_coords[:,j,i]\n",
    "        idx_no = np.squeeze(np.argwhere(np.array(TW_data_for_coordinate) <= threshold))\n",
    "        TW_data_JJA_pc = TW_data_for_coordinate[~idx_no] \n",
    "        #TW_percentile_cutoff_JJA[i][j] = np.nanpercentile(TW_data_JJA_pc, q=90)\n",
    "        TW_percentile_cutoff_JJA[i][j] = np.nanpercentile(TW_data_for_coordinate, q=90)\n",
    "        idx_90_TW = np.squeeze(np.argwhere(np.array(TW_data_for_coordinate) > TW_percentile_cutoff_JJA[i][j])) # put into index array\n",
    "        #idx_90_TW = (np.argwhere(np.array(TW_data_for_coordinate) > TW_percentile_cutoff_JJA[i][j])) # put into index array\n",
    "        #idx_90_TW = np.squeeze(np.array(TW_data_for_coordinate))\n",
    "        TW_90_pc = TW_data_for_coordinate[idx_90_TW] # select TW anomalies for this index\n",
    "        TW_90_idx = TW_90_pc.time.to_dataframe() # put into dataframe, list of dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e69051e-0b48-48d2-950e-9c6e2a903b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### PRECIP ANOMALY DAYS INDEX ###\n",
    "#precip_90_idx2 = precip_90_idx.iloc[:2]\n",
    "#max_percentile_idx = np.unravel_index(raw_percentile_cutoff_JJA.argmax(), raw_percentile_cutoff_JJA.shape)\n",
    "        \n",
    "for index, row in precip_90_idx.iterrows():\n",
    "            \n",
    "    # Buffer before\n",
    "    buffer = 5\n",
    "    date_datetime = index\n",
    "    #date_datetime = datetime.strptime(date,'%Y-%m-%d')\n",
    "            #date_datetime = datetime.strptime(date,'%Y-%m-%d') #turn into datetime \n",
    "    for addition in range(-1*buffer, 0): #5 days before, put actual day\n",
    "        backward = date_datetime + timedelta(days = addition)\n",
    "        precip_days.extend([backward])\n",
    "                \n",
    "                #First day aka day of\n",
    "    precip_days.extend([date_datetime])\n",
    "\n",
    "    for addition in range(1, buffer+1): # 5 days after event\n",
    "        forward = date_datetime + timedelta(days = addition)\n",
    "        precip_days.extend([forward])\n",
    "        \n",
    "precip_days_list = list(precip_days)\n",
    "\n",
    "#for ind, ts in enumerate(precip_days_list):\n",
    " #   precip_days_list[ind] = precip_days_list[ind].to_datetime #convert to datetime64\n",
    "    \n",
    "#for ind, ts in enumerate(precip_days_list):\n",
    "#    precip_days_list[ind] = precip_days_list[ind].from_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed723643-f5c0-4576-a498-9ffad3916197",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TW ANOMALY DAYS INDEX ###\n",
    "        \n",
    "for index, row in TW_90_idx.iterrows():\n",
    "            \n",
    "    # Buffer before\n",
    "    buffer = 5\n",
    "    date_datetime = index\n",
    "    #date_datetime = datetime.strptime(date,'%Y-%m-%d')\n",
    "            #date_datetime = datetime.strptime(date,'%Y-%m-%d') #turn into datetime \n",
    "    for addition in range(-1*buffer, 0): #5 days before, put actual day\n",
    "        backward = date_datetime + timedelta(days = addition)\n",
    "        TW_days.extend([backward])\n",
    "                \n",
    "                #First day aka day of\n",
    "    TW_days.extend([date_datetime])\n",
    "\n",
    "    for addition in range(1, buffer+1): # 5 days after event\n",
    "        forward = date_datetime + timedelta(days = addition)\n",
    "        TW_days.extend([forward])\n",
    "        \n",
    "TW_days_list = list(TW_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0d1663-3be9-4337-8bba-312883027c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Select +5/-5 days of Precip data ### \n",
    "\n",
    "#precip_days_tp = precip_data.where(precip_data.time.isin(precip_days_list), drop=True)\n",
    "#precip_days_tp = precip_data.sel(time=precip_days_list)\n",
    "\n",
    "#ABS mag\n",
    "#precip_days_tp = precip_data_year.sel(time=precip_days_list)\n",
    "precip_days_TW = precip_data_year.sel(time=TW_days_list)\n",
    "\n",
    "#anomalies\n",
    "#precip_days_tp = precip_data_anom.sel(time=precip_days_list)\n",
    "#precip_days_TW = precip_data_anom.sel(time=TW_days_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d0a858-defa-417c-890c-19338b1a302c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Select +5/-5 days of TW data ###\n",
    "\n",
    "#TW_days_tp = TW_unique.where(TW_unique.time.isin(precip_days_list), drop=True)\n",
    "#TW_days_tp = TW_unique.sel(time=precip_days_list)\n",
    "TW_days_TW = TW_unique.sel(time=TW_days_list)\n",
    "\n",
    "#TW_days_tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26f64ff-4be3-43d7-ba5a-01807bfffcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Select +5/-5 days of Specific Humidity ###\n",
    "\n",
    "#Spechum_days_tp = spechum_data.where(spechum_data.time.isin(precip_days_list), drop=True)\n",
    "Spechum_days_tp = spechum_data.sel(time=precip_days_list)\n",
    "Spechum_days_TW = spechum_data.sel(time=TW_days_list)\n",
    "\n",
    "#Select +5/-5 days of dry bulb temperature days\n",
    "#Temp_days_tp = temp_data.where(temp_data.time.isin(precip_days_list), drop=True)\n",
    "Temp_days_tp = temp_data.sel(time=precip_days_list)\n",
    "Temp_days_TW = temp_data.sel(time=TW_days_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57021085-7c86-44ce-bde3-dbecc0da90b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "###vv and soil m select ###\n",
    "# anomalies = vv_data\n",
    "# daily mean = vv_mean\n",
    "#abs mag = vv_mag\n",
    "\n",
    "#vv_days_tp = vv_unique.sel(time=precip_days_list)\n",
    "#vv_days_TW = vv_unique.sel(time=TW_days_list)\n",
    "\n",
    "\n",
    "#soil_days_tp = soil_unique.sel(time=precip_days_list)\n",
    "soil_days_TW = soil_unique.sel(time=TW_days_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada0629b-56f5-4f03-9a64-fb7c504746b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### convert to dataframe ###\n",
    "\n",
    "# RUN THIS IF CONDITIONING ON PRECIP\n",
    "\n",
    "TW_df = TW_days_tp.to_dataframe()\n",
    "precip_df = precip_days_tp.to_dataframe()\n",
    "#spechum_df = Spechum_days_tp.to_dataframe()\n",
    "#temp_df = Temp_days_tp.to_dataframe()\n",
    "precip_df.tp\n",
    "#vv_df = vv_days_tp.to_dataframe()\n",
    "soil_df = soil_days_tp.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadfcb3d-1f26-40d1-92eb-63c84469a1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS IF CONDITIONING ON TW\n",
    "TW_df = TW_days_TW.to_dataframe()\n",
    "precip_df = precip_days_TW.to_dataframe()\n",
    "#spechum_df = Spechum_days_TW.to_dataframe()\n",
    "#temp_df = Temp_days_TW.to_dataframe()\n",
    "precip_df.tp\n",
    "#vv_df = vv_days_TW.to_dataframe()\n",
    "soil_df = soil_days_TW.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d2e669-f1a7-49fa-ac18-58483fe9510f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add onset number and day number to dataframe\n",
    "buffer_range = 2*buffer + 1 # (number of days spanning each plot -- 5 before, 1 day of, 5 after) -- should be 11\n",
    "num_breaks = len(TW_df)/buffer_range #num_breaks should be a whole number --length(df)/11 = chunks of 11 day events\n",
    "break_count = np.arange(1,num_breaks+1,1) #breaks = events -- 1 to # of events list\n",
    "\n",
    "#days_before = np.arange(-1*buffer, 1,1) \n",
    "#days_after = np.arange(1, buffer + 1, 1) \n",
    "#days = np.hstack((days_before,days_after))\n",
    "# I think you can also just skip the four lines above and do: days = np.arange(-1*buffer, buffer + 1, 1)\n",
    "days = np.arange(-1*buffer, buffer + 1, 1) #x axis (-5 to +5)\n",
    "\n",
    "# Stack repeating list of the day numbers in a column and add an event count\n",
    "#day_array = np.tile(days,int(num_breaks)) #Construct an array by repeating 'days' the number of times given by int(num_breaks)\n",
    "day_array = np.tile(days,int(num_breaks)) #stack everytime you have an event, grouped by event #\n",
    "onset_array = np.repeat(break_count,buffer_range) #column of event numbers\n",
    "\n",
    "TW_df['Event Number'] = onset_array\n",
    "TW_df['Day Number'] = day_array\n",
    "TW_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e08b18a-adbc-4e40-b4f7-1fa323e60448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average across all events \n",
    "group_mean = TW_df.groupby('Day Number').mean()\n",
    "\n",
    "# Find standard devations across all events\n",
    "group_std = TW_df.groupby('Day Number').std()\n",
    "\n",
    "# Add +/- 1 std and +/- 2 std to dataframe columns\n",
    "group_mean['up_2std'] = group_mean['TW'] + 2*group_std['TW']\n",
    "group_mean['down_2std'] = group_mean['TW'] - 2*group_std['TW']\n",
    "group_mean['up_1std'] = group_mean['TW'] + group_std['TW']\n",
    "group_mean['down_1std'] = group_mean['TW'] - group_std['TW']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebc36b6-1068-472c-809f-e3538ecf65c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 'Wet Bulb Temperature Anomalies surrounding Extreme Precipitation: Region X'\n",
    "\n",
    "labels = [f'Break {i}' for i in range(1, int(num_breaks)+1)]\n",
    "labels.append('Average')\n",
    "\n",
    "xticks = [-5,-4,-3,-2,-1,0,1,2,3,4,5]\n",
    "xlabels = [-5,-4,-3,-2,-1,0,1,2,3,4,5]\n",
    "\n",
    "yticks = [-5,-4,-3,-2,-1,0,1,2,3,4,5,6,7]\n",
    "ylabels = [-5,-4,-3,-2,-1,0,1,2,3,4,5,6,7]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6,6), facecolor='w', edgecolor='k')\n",
    "\n",
    "for label in (ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "    label.set_fontsize(20)\n",
    "\n",
    "# Plot black line for overall composite mean\n",
    "mean_line = group_mean.reset_index().plot(ax = ax, x = 'Day Number', y = 'TW', color = 'black', label = labels[-1], linewidth = 5, kind = 'line')\n",
    "\n",
    "# Shade between +/- 1 std\n",
    "shading = ax.fill_between(group_mean.index,group_mean['up_1std'],group_mean['down_1std'], color = 'k', alpha = 0.4)\n",
    "\n",
    "# Horizontal line at y = 0\n",
    "ax.axhline(y=0, color='gray', linestyle='--', linewidth = 3)\n",
    "ax.axvline(x=0, color='gray', linestyle='--', linewidth = 3)\n",
    "\n",
    "# Shade around extreme precip day\n",
    "#ax.axvspan(-1, 1, alpha=0.25, color='grey')    \n",
    "\n",
    "plt.xlabel('Time Before/After Event', fontsize = 20)\n",
    "plt.ylabel('Wet Bulb Temperature Anomaly (℃)', fontsize = 20)\n",
    "#plt.title('Wet Bulb Temperature Anomalies surrounding Extreme Precipitation: Region 4')\n",
    "ax.get_legend().remove()\n",
    "\n",
    "ax.set_xticks(xticks)\n",
    "ax.set_xticklabels(xlabels)\n",
    "ax.set_yticks(yticks)\n",
    "ax.set_yticklabels(ylabels)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841ac03b-73cc-4cf9-9087-d55add5a2ee3",
   "metadata": {},
   "source": [
    "## Soil Moisture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd4430b-d979-4e12-a0b3-e5cb0a4c1676",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if conditioned on precip\n",
    "#soil_df = soil_days_tp.to_dataframe()\n",
    "\n",
    "#if conditioned on TW\n",
    "soil_df = soil_days_TW.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17edb1e-4313-4bb4-9c0a-e11c0c2b2c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add onset number and day number to dataframe\n",
    "soil_df['Event Number'] = onset_array #[0:len(temp_df),]\n",
    "soil_df['Day Number'] = day_array #[0:len(temp_df),]\n",
    "\n",
    "# Average across all breaks\n",
    "group_mean_soil = soil_df.groupby('Day Number').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75628a4b-4a2a-475a-af84-e154e7bd57bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take standard deviation across all breaks\n",
    "group_std_soil = soil_df.groupby('Day Number').std()\n",
    "\n",
    "# Add +/- 1 and 2 std to dataframe\n",
    "group_mean_soil['up_2std'] = group_mean_soil['swvl1'] + 2*group_std_soil['swvl1']\n",
    "group_mean_soil['down_2std'] = group_mean_soil['swvl1'] - 2*group_std_soil['swvl1']\n",
    "group_mean_soil['up_1std'] = group_mean_soil['swvl1'] + group_std_soil['swvl1']\n",
    "group_mean_soil['down_1std'] = group_mean_soil['swvl1'] - group_std_soil['swvl1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613455ed-a8bf-412a-b548-5bb4ce2c1c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [f'Break {i}' for i in range(1, int(num_breaks)+1)]\n",
    "labels.append('Average')\n",
    "\n",
    "#yticks = [-.1,0,.05,.1,.15,.2]\n",
    "#ylabels = [-.1,0,.05,.1,.15,.2]\n",
    "\n",
    "yticks = [-.1,-.05,0,.05,.1]\n",
    "ylabels = [-.1,-.05,0,.05,.1]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6,6), facecolor='w', edgecolor='k')\n",
    "\n",
    "for label in (ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "    label.set_fontsize(20)\n",
    "\n",
    "# Plot black line as mean over all composite events\n",
    "mean_line = group_mean_soil.reset_index().plot(ax = ax, x = 'Day Number', y = 'swvl1', color = 'firebrick', label = labels[-1], linewidth = 5, kind = 'line')\n",
    "\n",
    "# Shade +/- 1 std\n",
    "shading = ax.fill_between(group_mean_soil.index,group_mean_soil['up_1std'],group_mean_soil['down_1std'], color = 'firebrick', alpha = 0.4)\n",
    "\n",
    "# Add horizontal line at y = 0\n",
    "ax.axhline(y=0, color='gray', linestyle='--', linewidth = 3)\n",
    "ax.axvline(x=0, color='gray', linestyle='--', linewidth = 3)\n",
    "  \n",
    "# Shade over duration of monsoon break\n",
    "#ax.axvspan(-1, 1, alpha=0.25, color='grey')    \n",
    "plt.xlabel('Time Before/After Event', fontsize = 20)\n",
    "plt.ylabel('Soil Moisture Anomaly (m$^3$/m$^3$)', fontsize = 20)\n",
    "#plt.title('Dry Bulb Temperature Anomalies surrounding Extreme Precipitation: Region 4')\n",
    "ax.get_legend().remove()\n",
    "\n",
    "ax.set_xticks(xticks)\n",
    "ax.set_xticklabels(xlabels)\n",
    "ax.set_yticks(yticks)\n",
    "ax.set_yticklabels(ylabels)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27527c12-6be0-4cbd-85d5-09ef21111bca",
   "metadata": {},
   "source": [
    "## Vertical Velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d10ca3-7d94-4062-b613-0688d99ba5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to pandas dataframe\n",
    "#vv_df = vv_days_tp.to_dataframe()\n",
    "vv_df = vv_days_TW.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187d6a7d-6ede-48ed-b138-338b36eef744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add onset number and day number to dataframe\n",
    "vv_df['Event Number'] = onset_array #[0:len(temp_df),]\n",
    "vv_df['Day Number'] = day_array #[0:len(temp_df),]\n",
    "\n",
    "# Average across all breaks\n",
    "group_mean_vv = vv_df.groupby('Day Number').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec63877-a0b7-4c3d-a42f-52096792c6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take standard deviation across all breaks\n",
    "group_std_vv = vv_df.groupby('Day Number').std()\n",
    "\n",
    "# Add +/- 1 and 2 std to dataframe\n",
    "group_mean_vv['up_2std'] = group_mean_vv['w'] + 2*group_std_vv['w']\n",
    "group_mean_vv['down_2std'] = group_mean_vv['w'] - 2*group_std_vv['w']\n",
    "group_mean_vv['up_1std'] = group_mean_vv['w'] + group_std_vv['w']\n",
    "group_mean_vv['down_1std'] = group_mean_vv['w'] - group_std_vv['w']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ee9720-06a0-4071-bc4d-2af08535dc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [f'Break {i}' for i in range(1, int(num_breaks)+1)]\n",
    "labels.append('Average')\n",
    "\n",
    "yticks = [-.2,-.15,-.1,-.05,0,.05,.1,.15,.2]\n",
    "ylabels = [-.2,-.15,-.1,-.05,0,.05,.1,.15,.2]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6,6), facecolor='w', edgecolor='k')\n",
    "\n",
    "for label in (ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "    label.set_fontsize(20)\n",
    "\n",
    "# Plot black line as mean over all composite events\n",
    "mean_line = group_mean_vv.reset_index().plot(ax = ax, x = 'Day Number', y = 'w', color = 'steelblue', label = labels[-1], linewidth = 5, kind = 'line')\n",
    "\n",
    "# Shade +/- 1 std\n",
    "shading = ax.fill_between(group_mean_vv.index,group_mean_vv['up_1std'],group_mean_vv['down_1std'], color = 'steelblue', alpha = 0.4)\n",
    "\n",
    "# Add horizontal line at y = 0\n",
    "ax.axhline(y=0, color='gray', linestyle='--', linewidth = 3)\n",
    "ax.axvline(x=0, color='gray', linestyle='--', linewidth = 3)\n",
    "  \n",
    "# Shade over duration of monsoon break\n",
    "#ax.axvspan(-1, 1, alpha=0.25, color='grey')    \n",
    "plt.xlabel('Time Before/After Event', fontsize = 20)\n",
    "plt.ylabel('Vertical Velocity Anomaly (Pa/s)', fontsize = 20) #Vertical Velocity (Pa/s)\n",
    "#plt.title('Dry Bulb Temperature Anomalies surrounding Extreme Precipitation: Region 4')\n",
    "ax.get_legend().remove()\n",
    "\n",
    "ax.set_xticks(xticks)\n",
    "ax.set_xticklabels(xlabels)\n",
    "ax.set_yticks(yticks)\n",
    "ax.set_yticklabels(ylabels)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fecc31-4dcd-480a-972c-42608e6abce7",
   "metadata": {},
   "source": [
    "## Specific Humidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c209bf9-99ad-4a7b-8502-dc6877f858c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select daily mean specific humidity during extreme precip onset and surrounding\n",
    "#Spechum_days_tp = spechum_data.where(spechum_data.time.isin(precip_days_list), drop=True)\n",
    "\n",
    "# Convert to pandas dataframe\n",
    "#SH_df = Spechum_days_tp.to_dataframe()\n",
    "SH_df = Spechum_days_TW.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d78190-7351-429f-b9d2-b62abe8dcb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add onset number and day number to dataframe\n",
    "SH_df['Event Number'] = onset_array[0:len(SH_df),]\n",
    "SH_df['Day Number'] = day_array[0:len(SH_df),]\n",
    "\n",
    "# Average across all breaks\n",
    "group_mean_SH = SH_df.groupby('Day Number').mean()\n",
    "\n",
    "SH_df.q = SH_df.q*1000\n",
    "group_mean_SH.q = group_mean_SH.q*1000\n",
    "\n",
    "# Find standard devations across all breaks\n",
    "group_std_SH = SH_df.groupby('Day Number').std()\n",
    "\n",
    "# Add +/- 1 std and +/- 2 std to dataframe columns\n",
    "group_mean_SH['up_2std'] = group_mean_SH.q + 2*group_std_SH.q\n",
    "group_mean_SH['down_2std'] = group_mean_SH.q - 2*group_std_SH.q\n",
    "group_mean_SH['up_1std'] = group_mean_SH.q + group_std_SH.q\n",
    "group_mean_SH['down_1std'] = group_mean_SH.q - group_std_SH.q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d23bdf-d118-4781-950d-1d715662802e",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [f'Break {i}' for i in range(1, int(num_breaks)+1)]\n",
    "labels.append('Average')\n",
    "\n",
    "yticks = [-2,-1,0,1,2,3,4]\n",
    "ylabels = [-2,-1,0,1,2,3,4]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6,6), facecolor='w', edgecolor='k')\n",
    "\n",
    "for label in (ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "    label.set_fontsize(20)\n",
    "\n",
    "# Plot black mean line\n",
    "mean_line = group_mean_SH.reset_index().plot(ax = ax, x = 'Day Number', y = 'q', color = 'k', label = labels[-1], linewidth = 5, kind = 'line')\n",
    "\n",
    "# Shade between +/- 1 std\n",
    "shading = ax.fill_between(group_mean_SH.index,group_mean_SH['up_1std'],group_mean_SH['down_1std'], color = 'blue', alpha = 0.4)\n",
    "\n",
    "# Add horizontal line for y = 0\n",
    "ax.axhline(y=0, color='gray', linestyle='--', linewidth = 3)\n",
    "ax.axvline(x=0, color='gray', linestyle='--', linewidth = 3)\n",
    "\n",
    "# Shade break length\n",
    "#ax.axvspan(-1, 1, alpha=0.25, color='grey')    \n",
    "plt.xlabel('Time Before/After Event', fontsize = 20)\n",
    "plt.ylabel('Specific Humidity Anomaly (g/kg)', fontsize = 20)\n",
    "#plt.title('Specific Humidity Anomalies surrounding Extreme Precipitation: Region 4')\n",
    "ax.get_legend().remove()\n",
    "\n",
    "ax.set_xticks(xticks)\n",
    "ax.set_xticklabels(xlabels)\n",
    "ax.set_yticks(yticks)\n",
    "ax.set_yticklabels(ylabels)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb93c05-5a2b-4ad5-95f2-867d4bfbe2c6",
   "metadata": {},
   "source": [
    "## Dry Bulb Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0cd581-31e6-4916-95b9-ada287f5fc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select daily max wet bulb temperatures during extreme precipitation onset and surrounding\n",
    "#Temp_days_tp = temp_data.where(temp_data.time.isin(precip_days_list), drop=True)\n",
    "\n",
    "# Convert to pandas dataframe\n",
    "#temp_df = Temp_days_tp.to_dataframe()\n",
    "temp_df = Temp_days_TW.to_dataframe()\n",
    "#temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871c2300-6708-4b14-aef4-a2396c2c176f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add onset number and day number to dataframe\n",
    "temp_df['Event Number'] = onset_array #[0:len(temp_df),]\n",
    "temp_df['Day Number'] = day_array #[0:len(temp_df),]\n",
    "\n",
    "# Average across all breaks\n",
    "group_mean_temp = temp_df.groupby('Day Number').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6339f558-0431-4238-943f-03bfc0ac2e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take standard deviation across all breaks\n",
    "group_std_temp = temp_df.groupby('Day Number').std()\n",
    "\n",
    "# Add +/- 1 and 2 std to dataframe\n",
    "group_mean_temp['up_2std'] = group_mean_temp['t2m'] + 2*group_std_temp['t2m']\n",
    "group_mean_temp['down_2std'] = group_mean_temp['t2m'] - 2*group_std_temp['t2m']\n",
    "group_mean_temp['up_1std'] = group_mean_temp['t2m'] + group_std_temp['t2m']\n",
    "group_mean_temp['down_1std'] = group_mean_temp['t2m'] - group_std_temp['t2m']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ab3ba5-08a8-4eb3-b4c1-dafacc93331f",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [f'Break {i}' for i in range(1, int(num_breaks)+1)]\n",
    "labels.append('Average')\n",
    "\n",
    "yticks = [-5,-4,-3,-2,-1,0,1,2,3,4,5]\n",
    "ylabels = [-5,-4,-3,-2,-1,0,1,2,3,4,5]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6,6), facecolor='w', edgecolor='k')\n",
    "\n",
    "for label in (ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "    label.set_fontsize(20)\n",
    "\n",
    "# Plot black line as mean over all composite events\n",
    "mean_line = group_mean_temp.reset_index().plot(ax = ax, x = 'Day Number', y = 't2m', color = 'k', label = labels[-1], linewidth = 5, kind = 'line')\n",
    "\n",
    "# Shade +/- 1 std\n",
    "shading = ax.fill_between(group_mean_temp.index,group_mean_temp['up_1std'],group_mean_temp['down_1std'], color = 'red', alpha = 0.4)\n",
    "\n",
    "# Add horizontal line at y = 0\n",
    "ax.axhline(y=0, color='gray', linestyle='--', linewidth = 3)\n",
    "ax.axvline(x=0, color='gray', linestyle='--', linewidth = 3)\n",
    "  \n",
    "# Shade over duration of monsoon break\n",
    "#ax.axvspan(-1, 1, alpha=0.25, color='grey')    \n",
    "plt.xlabel('Time Before/After Event', fontsize = 20)\n",
    "plt.ylabel('Temperature Anomaly (℃)', fontsize = 20)\n",
    "#plt.title('Dry Bulb Temperature Anomalies surrounding Extreme Precipitation: Region 4')\n",
    "ax.get_legend().remove()\n",
    "\n",
    "ax.set_xticks(xticks)\n",
    "ax.set_xticklabels(xlabels)\n",
    "ax.set_yticks(yticks)\n",
    "ax.set_yticklabels(ylabels)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de38ec47-1851-4538-8801-927807b6fb5c",
   "metadata": {},
   "source": [
    "## Precipitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53ddd61-ce2e-4f06-8261-4a84e2115959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select daily max wet bulb temperatures during extreme precipitation onset and surrounding\n",
    "#precip_days_tp = precip_data.where(precip_data.time.isin(precip_days_list), drop=True)\n",
    "\n",
    "# Convert to pandas dataframe\n",
    "#precip_df = precip_days_tp.to_dataframe()\n",
    "precip_df = precip_days_TW.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e10375-077e-4ef7-83e6-a4de2df6e2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add onset number and day number to dataframe\n",
    "precip_df['Event Number'] = onset_array[0:len(precip_df),]\n",
    "precip_df['Day Number'] = day_array[0:len(precip_df),]\n",
    "\n",
    "# Average across all breaks\n",
    "group_mean_precip = precip_df.groupby('Day Number').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77c3337-61f2-469f-8227-adff474735b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take standard deviation across all breaks\n",
    "group_std_precip = precip_df.groupby('Day Number').std()\n",
    "\n",
    "# Add +/- 1 and 2 std to dataframe\n",
    "group_mean_precip['up_2std'] = group_mean_precip['tp'] + 2*group_std_precip['tp']\n",
    "group_mean_precip['down_2std'] = group_mean_precip['tp'] - 2*group_std_precip['tp']\n",
    "group_mean_precip['up_1std'] = group_mean_precip['tp'] + group_std_precip['tp']\n",
    "group_mean_precip['down_1std'] = group_mean_precip['tp'] - group_std_precip['tp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba45cb6-5752-452a-8ebb-fbf275c49854",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [f'Break {i}' for i in range(1, int(num_breaks)+1)]\n",
    "labels.append('Average')\n",
    "\n",
    "yticks = [0,5,10,15,20]\n",
    "ylabels = [0,5,10,15,20]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6,6), facecolor='w', edgecolor='k')\n",
    "\n",
    "for label in (ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "    label.set_fontsize(20)\n",
    "\n",
    "# Plot black line as mean over all composite events\n",
    "mean_line = group_mean_precip.reset_index().plot(ax = ax, x = 'Day Number', y = 'tp', color = 'k', label = labels[-1], linewidth = 5, kind = 'line')\n",
    "\n",
    "# Shade +/- 1 std\n",
    "shading = ax.fill_between(group_mean_precip.index,group_mean_precip['up_1std'],group_mean_precip['down_1std'], color = 'green', alpha = 0.4)\n",
    "\n",
    "# Add horizontal line at y = 0\n",
    "ax.axhline(y=0, color='gray', linestyle='--', linewidth = 3)\n",
    "ax.axvline(x=0, color='gray', linestyle='--', linewidth = 3)\n",
    "  \n",
    "# Shade over duration of monsoon break\n",
    "#ax.axvspan(-1, 1, alpha=0.25, color='grey')    \n",
    "plt.xlabel('Time Before/After Event', fontsize = 20)\n",
    "plt.ylabel('Precipitation Anomaly (mm)', fontsize = 20)\n",
    "#plt.title('Extreme Precipitation: Region 4')\n",
    "ax.get_legend().remove()\n",
    "\n",
    "ax.set_xticks(xticks)\n",
    "ax.set_xticklabels(xlabels)\n",
    "ax.set_yticks(yticks)\n",
    "ax.set_yticklabels(ylabels)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3937791-3b74-46c8-ad63-8334f7475149",
   "metadata": {},
   "source": [
    "## Precip and WBT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e43979d-4425-4688-9f13-2456d9a34791",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.legend_handler import HandlerLine2D\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(6,6), facecolor='w', edgecolor='k')\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "yticks = [-5,0,5,10,15,20,25,30,35]\n",
    "ylabels = [-5,0,5,10,15,20,25,30,35]\n",
    "\n",
    "y1ticks = [-1,0,1,2,3,4,5,6,7]\n",
    "y1labels = [-1,0,1,2,3,4,5,6,7]\n",
    "\n",
    "for label in (ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "    label.set_fontsize(20)\n",
    "\n",
    "# Plot black line as mean over all composite events\n",
    "mean_line = group_mean_precip.reset_index().plot(ax = ax1, x = 'Day Number', y = 'tp', color = 'g', label = 'Mean Precipitation', linewidth = 5, kind = 'line')\n",
    "label = labels[-1]\n",
    "\n",
    "#temp mean line\n",
    "#mean_line = group_mean_temp.reset_index().plot(ax = ax2, x = 'Day Number', y = 't2m', color = 'r', label = labels[-1], linewidth = 5, kind = 'line')\n",
    "\n",
    "#specific humidity mean line\n",
    "#mean_line = group_mean_SH.reset_index().plot(ax = ax2, x = 'Day Number', y = 'q', color = 'blue', label = labels[-1], linewidth = 5, kind = 'line')\n",
    "\n",
    "#wet bulb temp mean line\n",
    "mean_line2 = group_mean.reset_index().plot(ax = ax2, x = 'Day Number', y = 'TW', color = 'black', label = 'Mean TW', linewidth = 5, kind = 'line')\n",
    "\n",
    "# Shade +/- 1 std\n",
    "shading = ax1.fill_between(group_mean_precip.index,group_mean_precip['up_1std'],group_mean_precip['down_1std'], color = 'green', alpha = 0.4)\n",
    "shading = ax2.fill_between(group_mean.index,group_mean['up_1std'],group_mean['down_1std'], color = 'grey', alpha = 0.4)\n",
    "\n",
    "\n",
    "# Add horizontal line at y = 0\n",
    "#ax1.axhline(y=0, color='green', linestyle='--', linewidth = 3)\n",
    "#ax2.axhline(y=0, color='k', linestyle='--', linewidth = 3)\n",
    "  \n",
    "labels = [\"Mean tp\",\"Average\", \"Mean TW\"]\n",
    "    \n",
    "# Shade over duration of monsoon break\n",
    "#ax1.axvspan(-1, 1, alpha=0.25, color='grey')   \n",
    "ax1.axvline(x=0, color='gray', linestyle='--', linewidth = 3)\n",
    "ax1.axhline(y=0, color='gray', linestyle='--', linewidth = 3)\n",
    "\n",
    "\n",
    "ax1.set_xlabel('Time Before/After Event', fontsize = 16)\n",
    "ax1.set_ylabel('Precipitation Anomaly (mm)', fontsize = 16)\n",
    "ax1.legend(\"tp\")\n",
    "ax1.legend(['mean precip'], loc='upper left')\n",
    "#ax1.set_yticks(yticks)\n",
    "#ax1.set_yticklabels(ylabels)\n",
    "ax1.get_legend().remove()\n",
    "ax1.set_yticks(y1ticks)\n",
    "ax1.set_yticklabels(y1labels,fontsize = 16)\n",
    "\n",
    "ax2.set_ylabel('Wet Bulb Temperature Anomaly (℃)', fontsize = 16)\n",
    "ax2.legend(\"TW\")\n",
    "ax2.legend(['mean TW'], loc='upper right')\n",
    "ax2.get_legend().remove()\n",
    "ax2.set_yticks(yticks)\n",
    "ax2.set_yticklabels(ylabels,fontsize = 16)\n",
    "\n",
    "ax1.set_xticks(xticks)\n",
    "ax1.set_xticklabels(xlabels,fontsize = 16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb81f78e-6c7f-4ceb-b701-c4811a65995e",
   "metadata": {},
   "source": [
    "## Zoom in on Difference Map Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e275c50-df7b-4ab5-95c6-d55922b39f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "day_of_JJA = np.loadtxt('/RainHeatData/day_of_JJA.txt', delimiter = ',')\n",
    "day_of_JJA_precip = np.loadtxt('/RainHeatData/day_of_JJA_precip.txt', delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3e8b8e-1e0f-41cd-8456-c2ab130b432e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lats = np.argwhere((precip_data_JJA.lat.values >= 0) & (precip_data_JJA.lat.values <= 90))\n",
    "lons = np.argwhere((precip_data_JJA.lon.values >= 0) & (precip_data_JJA.lon.values <= 360))\n",
    "\n",
    "fig= plt.figure(figsize=(14,6))\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "extent = [240, 255, 30, 40] #15 X 10\n",
    "cm = plt.cm.get_cmap('coolwarm')\n",
    "res = '110m'\n",
    "\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "\n",
    "ax.set_extent(extent)\n",
    "#ax.gridlines()\n",
    "ax.add_feature(cfeature.COASTLINE.with_scale(res))\n",
    "ax.add_feature(cfeature.BORDERS.with_scale(res))\n",
    "ax.add_feature(cfeature.LAND.with_scale(res))\n",
    "ax.add_feature(cfeature.STATES.with_scale(res))\n",
    "\n",
    "gl = ax.gridlines(draw_labels=True)\n",
    "gl.top_labels = False\n",
    "gl.right_labels = False\n",
    "\n",
    "#pcolormesh plot\n",
    "sc = plt.pcolormesh(precip_data_JJA.lon.values[lons[:,0]], precip_data_JJA.lat.values[lats[:,0]], day_of_JJA,transform=ccrs.PlateCarree(), cmap='coolwarm') #coolwarm, BrBG\n",
    "#norm=divnorm\n",
    "#pcolormesh\n",
    "#sm = plt.pcolormesh(precip_data_JJA.lon.values[lons[:,0]], precip_data_JJA.lat.values[lats[:,0]], np.ma.masked_less(day_of_DJF_sigmask, 0), facecolor = 'None', edgecolors = None)\n",
    "\n",
    "# Add inset map\n",
    "#from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "#axins = inset_axes(ax, width=\"60%\", height=\"60%\", loc='lower left',\n",
    "                   #bbox_to_anchor=(-0.05, 0.2, 0.5, 0.5),\n",
    " #                  bbox_to_anchor=(.05, .2, .5, .5),\n",
    "  #                 bbox_transform=ax.transAxes,\n",
    "   #                axes_class=cartopy.mpl.geoaxes.GeoAxes,\n",
    "    #               axes_kwargs=dict(map_projection=ccrs.PlateCarree()))\n",
    "\n",
    "# Add land, state borders, coastline, and country borders to inset map\n",
    "#axins.add_feature(cartopy.feature.LAND.with_scale(res), facecolor='k', alpha=0.8, zorder=0)\n",
    "#axins.add_feature(cartopy.feature.COASTLINE.with_scale(res))\n",
    "#axins.add_feature(cartopy.feature.BORDERS.with_scale(res))\n",
    "\n",
    "# Set the lat/lon limits of the inset map [x0, x1, y0, y1]\n",
    "inset_extent = [247.5, 249.5, 32.5, 34.5]\n",
    "#ax.set_extent(inset_extent)\n",
    "\n",
    "# Add box around location of inset map on the main map\n",
    "x = [inset_extent[0], inset_extent[1], inset_extent[1], inset_extent[0], inset_extent[0]]\n",
    "y = [inset_extent[2], inset_extent[2], inset_extent[3], inset_extent[3], inset_extent[2]]\n",
    "ax.plot(x, y,color='blue', alpha=1.0, linewidth=6.0,transform=ccrs.PlateCarree())\n",
    "\n",
    "# Draw lines between inset map and box on main map\n",
    "#rect, connectors = ax.indicate_inset_zoom(axins, edgecolor=\"black\", alpha=0.5, transform=ax.transAxes)\n",
    "# By default only two of the connecting lines (connectors) are shown\n",
    "# it is possible to choose which of the lines to show by setting the visibility\n",
    "# connectors are counted clockwise from the lower-left corner\n",
    "#connectors[0].set_visible(False)\n",
    "#connectors[1].set_visible(True)\n",
    "#connectors[3].set_visible(True)\n",
    "#connectors[2].set_visible(True)\n",
    "\n",
    "#ax.set_xticklabels(top_labels,fontsize=20)\n",
    "#ax.set_yticklabels(right_labels,fontsize=20)\n",
    "\n",
    "cax = fig.add_axes([ax.get_position().x1+0.01,ax.get_position().y0,0.02,ax.get_position().height])\n",
    "#ax.set_title('Difference in Mean Extreme Wet Bulb Temperature Anomaly on Extreme Precipitation Anomaly Days (90%, JJA) vs All Days')\n",
    "plt.colorbar(sc ,cax=cax) # Similar to fig.colorbar(im, cax = cax) sc, cax=cax\n",
    "plt.clim(-2.5,2.5)\n",
    "plt.rc('axes', labelsize=20)\n",
    "#-2.5-2.5 for TW, -4-4 for Precip\n",
    "#-5+5 for t2m, -8+8 for precip\n",
    "\n",
    "#plt.savefig('/RainHeatData/FinalFigs/Region1_boxed_mean_TW_diff_dayofavg.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7141e2-c565-4f24-b7a5-28ab54400f40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821bac08-edf5-4df8-b5ea-ffd6eda80fc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a17bbf-3a32-46d8-8d36-84486b086aa4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
